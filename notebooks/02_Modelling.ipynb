{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71d267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from utils import automated_pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8fd34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 643 entries, 0 to 642\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id_pasien        643 non-null    int64         \n",
      " 1   tgl_pemeriksaan  643 non-null    datetime64[ns]\n",
      " 2   usia             643 non-null    Int64         \n",
      " 3   jk               643 non-null    Int64         \n",
      " 4   eritrosit        643 non-null    float64       \n",
      " 5   hematokrit       643 non-null    float64       \n",
      " 6   MCHC             643 non-null    float64       \n",
      " 7   MCH              643 non-null    float64       \n",
      " 8   MCV              643 non-null    float64       \n",
      " 9   hemoglobin       643 non-null    float64       \n",
      " 10  leukosit         643 non-null    Int64         \n",
      " 11  trombosit        643 non-null    Int64         \n",
      " 12  epo              643 non-null    Int64         \n",
      "dtypes: Int64(5), datetime64[ns](1), float64(6), int64(1)\n",
      "memory usage: 68.6 KB\n"
     ]
    }
   ],
   "source": [
    "file_raw = r'E:\\airta drafts\\PREDIKSI KADAR HB\\data\\raw\\erm_hd.xlsx'\n",
    "df_raw = pd.read_excel(file_raw)\n",
    "\n",
    "df = automated_pipeline(df_raw)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae2aad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baris data: 571\n",
      "Jumlah Data Latih (80%): 456\n",
      "Jumlah Data Uji (20%): 115\n",
      "------------------------------\n",
      "Fitur yang digunakan (X): ['usia', 'jk', 'eritrosit', 'hematokrit', 'MCHC', 'MCH', 'MCV', 'leukosit', 'trombosit', 'epo', 'hb_now']\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=['tgl_pemeriksaan', 'id_pasien']).reset_index(drop=True)\n",
    "\n",
    "#LAG FEATURE untuk TSCV\n",
    "df['hb_now'] = df.groupby('id_pasien')['hemoglobin'].shift(1)\n",
    "df = df.dropna(subset=['hb_now']).reset_index(drop=True)\n",
    "\n",
    "#MENENTUKAN FITUR X DAN TARGET Y\n",
    "X = df.drop(columns=['id_pasien', 'tgl_pemeriksaan', 'hemoglobin'])\n",
    "y = df['hemoglobin']\n",
    "\n",
    "#SPLIT 80:20 BERDASARKAN KRONOLOGIS\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Total baris data: {len(df)}\")\n",
    "print(f\"Jumlah Data Latih (80%): {len(X_train)}\")\n",
    "print(f\"Jumlah Data Uji (20%): {len(X_test)}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Fitur yang digunakan (X):\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4540ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baris di X_train: 456\n",
      "------------------------------\n",
      "Iterasi ke-1:\n",
      "  Jumlah Data Latih: 76 baris (Indeks 0 s/d 75)\n",
      "  Jumlah Data Validasi: 76 baris (Indeks 76 s/d 151)\n",
      "------------------------------\n",
      "Iterasi ke-2:\n",
      "  Jumlah Data Latih: 152 baris (Indeks 0 s/d 151)\n",
      "  Jumlah Data Validasi: 76 baris (Indeks 152 s/d 227)\n",
      "------------------------------\n",
      "Iterasi ke-3:\n",
      "  Jumlah Data Latih: 228 baris (Indeks 0 s/d 227)\n",
      "  Jumlah Data Validasi: 76 baris (Indeks 228 s/d 303)\n",
      "------------------------------\n",
      "Iterasi ke-4:\n",
      "  Jumlah Data Latih: 304 baris (Indeks 0 s/d 303)\n",
      "  Jumlah Data Validasi: 76 baris (Indeks 304 s/d 379)\n",
      "------------------------------\n",
      "Iterasi ke-5:\n",
      "  Jumlah Data Latih: 380 baris (Indeks 0 s/d 379)\n",
      "  Jumlah Data Validasi: 76 baris (Indeks 380 s/d 455)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Cek bagaimana TSCV membagi data X_train kamu\n",
    "print(f\"Total baris di X_train: {len(X_train)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(tscv.split(X_train)):\n",
    "    print(f\"Iterasi ke-{i+1}:\")\n",
    "    print(f\"  Jumlah Data Latih: {len(train_index)} baris (Indeks {train_index[0]} s/d {train_index[-1]})\")\n",
    "    print(f\"  Jumlah Data Validasi: {len(val_index)} baris (Indeks {val_index[0]} s/d {val_index[-1]})\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46faa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 23:31:39,146] A new study created in memory with name: no-name-756105ed-5bc3-46e3-b333-84aa2c5b04e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan Tuning SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 23:31:39,463] Trial 0 finished with value: 0.39625795859430707 and parameters: {'C': 1.6329705839213176, 'epsilon': 0.7881922204834645}. Best is trial 0 with value: 0.39625795859430707.\n",
      "[I 2026-02-04 23:31:39,676] Trial 1 finished with value: 0.32544036273629506 and parameters: {'C': 0.1526543388475578, 'epsilon': 0.01148173123662436}. Best is trial 1 with value: 0.32544036273629506.\n",
      "[I 2026-02-04 23:31:39,881] Trial 2 finished with value: 0.32042740490777605 and parameters: {'C': 0.3247763056603174, 'epsilon': 0.32067519918442866}. Best is trial 2 with value: 0.32042740490777605.\n",
      "[I 2026-02-04 23:31:40,072] Trial 3 finished with value: 0.2220361210144563 and parameters: {'C': 1.2622858277301936, 'epsilon': 0.19407377312522817}. Best is trial 3 with value: 0.2220361210144563.\n",
      "[I 2026-02-04 23:31:40,164] Trial 4 finished with value: 0.3417658665625399 and parameters: {'C': 78.65062661094423, 'epsilon': 0.6071855077589446}. Best is trial 3 with value: 0.2220361210144563.\n",
      "[I 2026-02-04 23:31:40,398] Trial 5 finished with value: 0.1565112131316683 and parameters: {'C': 8.397535359401678, 'epsilon': 0.011550325471382948}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:40,487] Trial 6 finished with value: 0.3956679180774768 and parameters: {'C': 0.14914814176119795, 'epsilon': 0.2667470831069488}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:40,605] Trial 7 finished with value: 0.21017711986856763 and parameters: {'C': 9.234277345575338, 'epsilon': 0.1503062281408344}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:40,692] Trial 8 finished with value: 0.2409250186768858 and parameters: {'C': 3.5786601185291826, 'epsilon': 0.26242165633963577}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:40,821] Trial 9 finished with value: 0.3396180362592479 and parameters: {'C': 0.16627770023480914, 'epsilon': 0.1382395230931517}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:41,149] Trial 10 finished with value: 0.1741442083556377 and parameters: {'C': 29.238750244682112, 'epsilon': 0.0179680748377531}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:41,442] Trial 11 finished with value: 0.17269578373033154 and parameters: {'C': 31.101643336755952, 'epsilon': 0.01168526892818874}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:41,639] Trial 12 finished with value: 0.1753003841109352 and parameters: {'C': 16.920646393601785, 'epsilon': 0.037729023435091213}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:41,866] Trial 13 finished with value: 0.19566110216710159 and parameters: {'C': 98.19893993485576, 'epsilon': 0.0492416789156915}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,045] Trial 14 finished with value: 0.1608968040101876 and parameters: {'C': 6.239281170994723, 'epsilon': 0.029277400726302562}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,228] Trial 15 finished with value: 0.15967650992801818 and parameters: {'C': 6.205552581957018, 'epsilon': 0.026289334470872724}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,365] Trial 16 finished with value: 0.19639254143328835 and parameters: {'C': 0.9030854696813645, 'epsilon': 0.08474906322203059}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,543] Trial 17 finished with value: 0.15711120286145278 and parameters: {'C': 3.3859325078910327, 'epsilon': 0.021307986644637733}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,687] Trial 18 finished with value: 0.1727111938410896 and parameters: {'C': 2.704240083993343, 'epsilon': 0.06545784971447645}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:42,860] Trial 19 finished with value: 0.20125740012713278 and parameters: {'C': 0.5755574762438542, 'epsilon': 0.017885799764201914}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:43,097] Trial 20 finished with value: 0.16350114366975993 and parameters: {'C': 12.983058726425737, 'epsilon': 0.01758847946438353}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:43,319] Trial 21 finished with value: 0.15943276326335543 and parameters: {'C': 4.672154116424311, 'epsilon': 0.029347669885447444}. Best is trial 5 with value: 0.1565112131316683.\n",
      "[I 2026-02-04 23:31:43,608] Trial 22 finished with value: 0.15643329900688574 and parameters: {'C': 2.5768994626080306, 'epsilon': 0.010128589900912827}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:43,788] Trial 23 finished with value: 0.1627003328894426 and parameters: {'C': 1.5897590725780775, 'epsilon': 0.010504750227618077}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:43,983] Trial 24 finished with value: 0.15784698792839616 and parameters: {'C': 2.6027489472836507, 'epsilon': 0.016881809803338692}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,136] Trial 25 finished with value: 0.2032994618215503 and parameters: {'C': 0.5488796573396219, 'epsilon': 0.010401497386672504}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,333] Trial 26 finished with value: 0.16135870204080738 and parameters: {'C': 8.63697330912914, 'epsilon': 0.023266986701419804}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,530] Trial 27 finished with value: 0.1804489216175718 and parameters: {'C': 22.824687629921193, 'epsilon': 0.042143130730071636}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,721] Trial 28 finished with value: 0.15808335644216612 and parameters: {'C': 2.439101162771503, 'epsilon': 0.015096309708794697}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,893] Trial 29 finished with value: 0.19642541479088962 and parameters: {'C': 42.83703818642707, 'epsilon': 0.06214125962195978}. Best is trial 22 with value: 0.15643329900688574.\n",
      "[I 2026-02-04 23:31:44,895] A new study created in memory with name: no-name-02743206-b979-4294-a043-95934c39c508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan Tuning Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 23:31:51,234] Trial 0 finished with value: 0.14672661461594144 and parameters: {'n_estimators': 295, 'max_depth': 6}. Best is trial 0 with value: 0.14672661461594144.\n",
      "[I 2026-02-04 23:31:53,155] Trial 1 finished with value: 0.1419316510466085 and parameters: {'n_estimators': 95, 'max_depth': 11}. Best is trial 1 with value: 0.1419316510466085.\n",
      "[I 2026-02-04 23:31:55,868] Trial 2 finished with value: 0.14123869610496162 and parameters: {'n_estimators': 122, 'max_depth': 14}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:31:58,645] Trial 3 finished with value: 0.14143815349061692 and parameters: {'n_estimators': 106, 'max_depth': 10}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:31:59,848] Trial 4 finished with value: 0.14407733412055784 and parameters: {'n_estimators': 50, 'max_depth': 12}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:02,859] Trial 5 finished with value: 0.14149271931927485 and parameters: {'n_estimators': 142, 'max_depth': 10}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:06,887] Trial 6 finished with value: 0.1753188258142294 and parameters: {'n_estimators': 269, 'max_depth': 4}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:10,362] Trial 7 finished with value: 0.14162238804683014 and parameters: {'n_estimators': 214, 'max_depth': 9}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:11,300] Trial 8 finished with value: 0.14791131486926976 and parameters: {'n_estimators': 54, 'max_depth': 6}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:12,219] Trial 9 finished with value: 0.15548708346524862 and parameters: {'n_estimators': 50, 'max_depth': 5}. Best is trial 2 with value: 0.14123869610496162.\n",
      "[I 2026-02-04 23:32:16,122] Trial 10 finished with value: 0.14052758999484458 and parameters: {'n_estimators': 198, 'max_depth': 15}. Best is trial 10 with value: 0.14052758999484458.\n",
      "[I 2026-02-04 23:32:20,013] Trial 11 finished with value: 0.14048534584617167 and parameters: {'n_estimators': 191, 'max_depth': 15}. Best is trial 11 with value: 0.14048534584617167.\n",
      "[I 2026-02-04 23:32:23,549] Trial 12 finished with value: 0.14052758999484458 and parameters: {'n_estimators': 198, 'max_depth': 15}. Best is trial 11 with value: 0.14048534584617167.\n",
      "[I 2026-02-04 23:32:28,128] Trial 13 finished with value: 0.14070374177395523 and parameters: {'n_estimators': 232, 'max_depth': 13}. Best is trial 11 with value: 0.14048534584617167.\n",
      "[I 2026-02-04 23:32:31,379] Trial 14 finished with value: 0.1405444588876288 and parameters: {'n_estimators': 173, 'max_depth': 15}. Best is trial 11 with value: 0.14048534584617167.\n",
      "[I 2026-02-04 23:32:34,184] Trial 15 finished with value: 0.14039473445195982 and parameters: {'n_estimators': 174, 'max_depth': 13}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:36,380] Trial 16 finished with value: 0.14233572483135046 and parameters: {'n_estimators': 159, 'max_depth': 8}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:40,239] Trial 17 finished with value: 0.14074697859627228 and parameters: {'n_estimators': 243, 'max_depth': 13}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:42,939] Trial 18 finished with value: 0.14168721581060462 and parameters: {'n_estimators': 147, 'max_depth': 13}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:46,524] Trial 19 finished with value: 0.1405899932562535 and parameters: {'n_estimators': 189, 'max_depth': 12}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:49,862] Trial 20 finished with value: 0.14205192881508127 and parameters: {'n_estimators': 245, 'max_depth': 8}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:52,979] Trial 21 finished with value: 0.1405833328631398 and parameters: {'n_estimators': 212, 'max_depth': 15}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:55,239] Trial 22 finished with value: 0.14051188182302715 and parameters: {'n_estimators': 182, 'max_depth': 14}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:57,858] Trial 23 finished with value: 0.14062117371641553 and parameters: {'n_estimators': 171, 'max_depth': 14}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:32:59,528] Trial 24 finished with value: 0.14124341787709013 and parameters: {'n_estimators': 132, 'max_depth': 12}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:01,936] Trial 25 finished with value: 0.14062381725831904 and parameters: {'n_estimators': 179, 'max_depth': 14}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:03,890] Trial 26 finished with value: 0.14146374466489517 and parameters: {'n_estimators': 154, 'max_depth': 14}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:06,813] Trial 27 finished with value: 0.14138791121282113 and parameters: {'n_estimators': 218, 'max_depth': 11}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:08,600] Trial 28 finished with value: 0.1408048381361221 and parameters: {'n_estimators': 107, 'max_depth': 13}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:12,658] Trial 29 finished with value: 0.14161041388374787 and parameters: {'n_estimators': 299, 'max_depth': 11}. Best is trial 15 with value: 0.14039473445195982.\n",
      "[I 2026-02-04 23:33:12,660] A new study created in memory with name: no-name-3fde1fee-7925-4ef5-8503-a0edd90800b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan Tuning LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 23:33:21,814] Trial 0 finished with value: 0.4490123706827525 and parameters: {'n_estimators': 149, 'learning_rate': 0.005120374389916627, 'max_depth': 9, 'num_leaves': 87}. Best is trial 0 with value: 0.4490123706827525.\n",
      "[I 2026-02-04 23:33:21,987] Trial 1 finished with value: 0.3199410656703777 and parameters: {'n_estimators': 117, 'learning_rate': 0.010644553759084052, 'max_depth': 10, 'num_leaves': 22}. Best is trial 1 with value: 0.3199410656703777.\n",
      "[I 2026-02-04 23:33:22,324] Trial 2 finished with value: 0.19105111511828993 and parameters: {'n_estimators': 270, 'learning_rate': 0.04756686303321451, 'max_depth': 7, 'num_leaves': 24}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:22,608] Trial 3 finished with value: 0.1927366284842246 and parameters: {'n_estimators': 226, 'learning_rate': 0.061303936754439944, 'max_depth': 9, 'num_leaves': 83}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:22,811] Trial 4 finished with value: 0.3592333111791535 and parameters: {'n_estimators': 173, 'learning_rate': 0.0061629198025178284, 'max_depth': 5, 'num_leaves': 31}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:23,055] Trial 5 finished with value: 0.19549237099931333 and parameters: {'n_estimators': 278, 'learning_rate': 0.05980472683098162, 'max_depth': 4, 'num_leaves': 22}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:23,263] Trial 6 finished with value: 0.33781278861545566 and parameters: {'n_estimators': 188, 'learning_rate': 0.00620951380069726, 'max_depth': 4, 'num_leaves': 20}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:23,475] Trial 7 finished with value: 0.20021019390904718 and parameters: {'n_estimators': 148, 'learning_rate': 0.017375619184221893, 'max_depth': 6, 'num_leaves': 50}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:23,813] Trial 8 finished with value: 0.2567748584745813 and parameters: {'n_estimators': 291, 'learning_rate': 0.005793805213504787, 'max_depth': 5, 'num_leaves': 69}. Best is trial 2 with value: 0.19105111511828993.\n",
      "[I 2026-02-04 23:33:23,979] Trial 9 finished with value: 0.18353967935143473 and parameters: {'n_estimators': 108, 'learning_rate': 0.05931821770833672, 'max_depth': 9, 'num_leaves': 79}. Best is trial 9 with value: 0.18353967935143473.\n",
      "[I 2026-02-04 23:33:24,111] Trial 10 finished with value: 0.23802788561695504 and parameters: {'n_estimators': 56, 'learning_rate': 0.033164979446059874, 'max_depth': 8, 'num_leaves': 99}. Best is trial 9 with value: 0.18353967935143473.\n",
      "[I 2026-02-04 23:33:24,259] Trial 11 finished with value: 0.18430617700120128 and parameters: {'n_estimators': 86, 'learning_rate': 0.08637770387293019, 'max_depth': 7, 'num_leaves': 51}. Best is trial 9 with value: 0.18353967935143473.\n",
      "[I 2026-02-04 23:33:24,398] Trial 12 finished with value: 0.1835130865255466 and parameters: {'n_estimators': 65, 'learning_rate': 0.09601040223250532, 'max_depth': 7, 'num_leaves': 50}. Best is trial 12 with value: 0.1835130865255466.\n",
      "[I 2026-02-04 23:33:24,524] Trial 13 finished with value: 0.18388867980725912 and parameters: {'n_estimators': 52, 'learning_rate': 0.09244008357673071, 'max_depth': 8, 'num_leaves': 64}. Best is trial 12 with value: 0.1835130865255466.\n",
      "[I 2026-02-04 23:33:24,691] Trial 14 finished with value: 0.19105618502560454 and parameters: {'n_estimators': 99, 'learning_rate': 0.030249892654587798, 'max_depth': 10, 'num_leaves': 45}. Best is trial 12 with value: 0.1835130865255466.\n",
      "[I 2026-02-04 23:33:24,843] Trial 15 finished with value: 0.1854818319979317 and parameters: {'n_estimators': 83, 'learning_rate': 0.09685821185556719, 'max_depth': 8, 'num_leaves': 75}. Best is trial 12 with value: 0.1835130865255466.\n",
      "[I 2026-02-04 23:33:25,008] Trial 16 finished with value: 0.1827447830909641 and parameters: {'n_estimators': 118, 'learning_rate': 0.043138462314847414, 'max_depth': 6, 'num_leaves': 39}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:25,193] Trial 17 finished with value: 0.19967981985099406 and parameters: {'n_estimators': 132, 'learning_rate': 0.019367612364371387, 'max_depth': 6, 'num_leaves': 38}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:25,321] Trial 18 finished with value: 0.20086683237658537 and parameters: {'n_estimators': 73, 'learning_rate': 0.038710180290122416, 'max_depth': 3, 'num_leaves': 58}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:25,551] Trial 19 finished with value: 0.1835475007105837 and parameters: {'n_estimators': 199, 'learning_rate': 0.02518043495019026, 'max_depth': 5, 'num_leaves': 38}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:25,749] Trial 20 finished with value: 0.25749421522317506 and parameters: {'n_estimators': 133, 'learning_rate': 0.012569731656711993, 'max_depth': 6, 'num_leaves': 55}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:25,917] Trial 21 finished with value: 0.18335442138297017 and parameters: {'n_estimators': 110, 'learning_rate': 0.05667247756859477, 'max_depth': 7, 'num_leaves': 41}. Best is trial 16 with value: 0.1827447830909641.\n",
      "[I 2026-02-04 23:33:26,052] Trial 22 finished with value: 0.18268743854671926 and parameters: {'n_estimators': 75, 'learning_rate': 0.07304988759552355, 'max_depth': 7, 'num_leaves': 44}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:26,206] Trial 23 finished with value: 0.18455960012864242 and parameters: {'n_estimators': 95, 'learning_rate': 0.04342721406715818, 'max_depth': 7, 'num_leaves': 40}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:26,384] Trial 24 finished with value: 0.18628824213052653 and parameters: {'n_estimators': 120, 'learning_rate': 0.07267038329974754, 'max_depth': 6, 'num_leaves': 33}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:26,700] Trial 25 finished with value: 0.18278947361246564 and parameters: {'n_estimators': 156, 'learning_rate': 0.050385670788060506, 'max_depth': 8, 'num_leaves': 31}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:26,912] Trial 26 finished with value: 0.18315505868323126 and parameters: {'n_estimators': 158, 'learning_rate': 0.03584236735055863, 'max_depth': 8, 'num_leaves': 32}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:27,159] Trial 27 finished with value: 0.18796133345316318 and parameters: {'n_estimators': 212, 'learning_rate': 0.048129275387183784, 'max_depth': 8, 'num_leaves': 29}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:27,424] Trial 28 finished with value: 0.18278497166365465 and parameters: {'n_estimators': 236, 'learning_rate': 0.02645031497603885, 'max_depth': 5, 'num_leaves': 44}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:27,722] Trial 29 finished with value: 0.18350497647229652 and parameters: {'n_estimators': 235, 'learning_rate': 0.02631525160174849, 'max_depth': 4, 'num_leaves': 44}. Best is trial 22 with value: 0.18268743854671926.\n",
      "[I 2026-02-04 23:33:27,723] A new study created in memory with name: no-name-2bee5392-65a1-4a90-a19d-d128b61aefb3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 23:33:28,808] Trial 0 finished with value: 0.48939607696441945 and parameters: {'n_estimators': 64, 'learning_rate': 0.010576487376901384, 'max_depth': 4}. Best is trial 0 with value: 0.48939607696441945.\n",
      "[I 2026-02-04 23:33:29,155] Trial 1 finished with value: 0.3906325405613658 and parameters: {'n_estimators': 50, 'learning_rate': 0.019435640366601392, 'max_depth': 6}. Best is trial 1 with value: 0.3906325405613658.\n",
      "[I 2026-02-04 23:33:29,617] Trial 2 finished with value: 0.14904507860460545 and parameters: {'n_estimators': 75, 'learning_rate': 0.04553156787287357, 'max_depth': 6}. Best is trial 2 with value: 0.14904507860460545.\n",
      "[I 2026-02-04 23:33:30,917] Trial 3 finished with value: 0.13668827455998234 and parameters: {'n_estimators': 236, 'learning_rate': 0.053838317414357226, 'max_depth': 7}. Best is trial 3 with value: 0.13668827455998234.\n",
      "[I 2026-02-04 23:33:31,628] Trial 4 finished with value: 0.1709755960354965 and parameters: {'n_estimators': 169, 'learning_rate': 0.015289987309827037, 'max_depth': 5}. Best is trial 3 with value: 0.13668827455998234.\n",
      "[I 2026-02-04 23:33:32,298] Trial 5 finished with value: 0.12546786381145042 and parameters: {'n_estimators': 164, 'learning_rate': 0.039868935677762084, 'max_depth': 5}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:33,651] Trial 6 finished with value: 0.3336654653138521 and parameters: {'n_estimators': 188, 'learning_rate': 0.006413950277196436, 'max_depth': 8}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:34,131] Trial 7 finished with value: 0.35904310854770355 and parameters: {'n_estimators': 103, 'learning_rate': 0.01055263637025748, 'max_depth': 5}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:35,113] Trial 8 finished with value: 0.2099903375315324 and parameters: {'n_estimators': 132, 'learning_rate': 0.015520136009255241, 'max_depth': 8}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:35,556] Trial 9 finished with value: 0.1300135164686748 and parameters: {'n_estimators': 123, 'learning_rate': 0.034088849891572924, 'max_depth': 3}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:37,073] Trial 10 finished with value: 0.13794149848110562 and parameters: {'n_estimators': 293, 'learning_rate': 0.08986402200920184, 'max_depth': 9}. Best is trial 5 with value: 0.12546786381145042.\n",
      "[I 2026-02-04 23:33:37,730] Trial 11 finished with value: 0.1246594657152654 and parameters: {'n_estimators': 147, 'learning_rate': 0.033875480490030044, 'max_depth': 3}. Best is trial 11 with value: 0.1246594657152654.\n",
      "[I 2026-02-04 23:33:38,719] Trial 12 finished with value: 0.12280472987234312 and parameters: {'n_estimators': 179, 'learning_rate': 0.031211048013956858, 'max_depth': 3}. Best is trial 12 with value: 0.12280472987234312.\n",
      "[I 2026-02-04 23:33:39,512] Trial 13 finished with value: 0.12379392253382929 and parameters: {'n_estimators': 192, 'learning_rate': 0.026452026260279378, 'max_depth': 3}. Best is trial 12 with value: 0.12280472987234312.\n",
      "[I 2026-02-04 23:33:40,466] Trial 14 finished with value: 0.12293143403815314 and parameters: {'n_estimators': 210, 'learning_rate': 0.025404352256494657, 'max_depth': 3}. Best is trial 12 with value: 0.12280472987234312.\n",
      "[I 2026-02-04 23:33:41,869] Trial 15 finished with value: 0.11981290865020514 and parameters: {'n_estimators': 228, 'learning_rate': 0.07061985967380176, 'max_depth': 4}. Best is trial 15 with value: 0.11981290865020514.\n",
      "[I 2026-02-04 23:33:43,165] Trial 16 finished with value: 0.11854515809419627 and parameters: {'n_estimators': 268, 'learning_rate': 0.08207621133729935, 'max_depth': 4}. Best is trial 16 with value: 0.11854515809419627.\n",
      "[I 2026-02-04 23:33:44,399] Trial 17 finished with value: 0.11647308246788993 and parameters: {'n_estimators': 264, 'learning_rate': 0.09530986932821019, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:46,183] Trial 18 finished with value: 0.13868092266794602 and parameters: {'n_estimators': 293, 'learning_rate': 0.099438604358853, 'max_depth': 10}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:47,345] Trial 19 finished with value: 0.11833827426216825 and parameters: {'n_estimators': 260, 'learning_rate': 0.06784031564799592, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:49,525] Trial 20 finished with value: 0.1357848769496693 and parameters: {'n_estimators': 259, 'learning_rate': 0.060448886959307994, 'max_depth': 7}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:50,843] Trial 21 finished with value: 0.11853423542801467 and parameters: {'n_estimators': 265, 'learning_rate': 0.07542012358494292, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:51,881] Trial 22 finished with value: 0.11875980483515984 and parameters: {'n_estimators': 265, 'learning_rate': 0.0608513742656106, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:52,875] Trial 23 finished with value: 0.1263918213851905 and parameters: {'n_estimators': 247, 'learning_rate': 0.07503876858191705, 'max_depth': 5}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:53,591] Trial 24 finished with value: 0.11792728346348573 and parameters: {'n_estimators': 223, 'learning_rate': 0.04933568314426997, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:54,721] Trial 25 finished with value: 0.13324315110500168 and parameters: {'n_estimators': 214, 'learning_rate': 0.04609126141950103, 'max_depth': 6}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:55,535] Trial 26 finished with value: 0.1253195878672258 and parameters: {'n_estimators': 214, 'learning_rate': 0.05626605901449648, 'max_depth': 5}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:56,355] Trial 27 finished with value: 0.11977104820360984 and parameters: {'n_estimators': 281, 'learning_rate': 0.09660950436243698, 'max_depth': 4}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:57,418] Trial 28 finished with value: 0.1328952671945381 and parameters: {'n_estimators': 240, 'learning_rate': 0.04945886690435886, 'max_depth': 6}. Best is trial 17 with value: 0.11647308246788993.\n",
      "[I 2026-02-04 23:33:58,188] Trial 29 finished with value: 0.1265269423124323 and parameters: {'n_estimators': 204, 'learning_rate': 0.03794357284892064, 'max_depth': 5}. Best is trial 17 with value: 0.11647308246788993.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TUNING SELESAI ---\n",
      "SVR MAE: -0.1564\n",
      "RF MAE: -0.1404\n",
      "LGBM MAE: -0.1827\n",
      "XGB MAE: -0.1165\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# --- FUNGSI OBJECTIVE UNTUK MASING-MASING MODEL ---\n",
    "\n",
    "def obj_svr(trial):\n",
    "    # Parameter SVR (C dan Epsilon sangat krusial di sini)\n",
    "    c = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 0.01, 1.0, log=True)\n",
    "    \n",
    "    # SVR WAJIB Scaling (StandardScaler)\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVR(C=c, epsilon=epsilon))\n",
    "    ])\n",
    "    score = cross_val_score(pipe, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    return -score.mean()\n",
    "\n",
    "def obj_rf(trial):\n",
    "    n_est = trial.suggest_int('n_estimators', 50, 300)\n",
    "    depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    model = RandomForestRegressor(n_estimators=n_est, max_depth=depth, random_state=42)\n",
    "    # RF tidak wajib scaling karena berbasis pohon\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    return -score.mean()\n",
    "\n",
    "def obj_lgbm(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = LGBMRegressor(**param, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    return -score.mean()\n",
    "\n",
    "def obj_xgb(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "    }\n",
    "    model = XGBRegressor(**param, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    return -score.mean()\n",
    "\n",
    "# --- EKSEKUSI TUNING (Bisa memakan waktu beberapa menit) ---\n",
    "\n",
    "print(\"Menjalankan Tuning SVR...\")\n",
    "study_svr = optuna.create_study(direction='minimize')\n",
    "study_svr.optimize(obj_svr, n_trials=30)\n",
    "\n",
    "print(\"Menjalankan Tuning Random Forest...\")\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(obj_rf, n_trials=30)\n",
    "\n",
    "print(\"Menjalankan Tuning LightGBM...\")\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "study_lgbm.optimize(obj_lgbm, n_trials=30)\n",
    "\n",
    "print(\"Menjalankan Tuning XGBoost...\")\n",
    "study_xgb = optuna.create_study(direction='minimize')\n",
    "study_xgb.optimize(obj_xgb, n_trials=30)\n",
    "\n",
    "print(\"\\n--- TUNING SELESAI ---\")\n",
    "print(f\"SVR MAE: {-study_svr.best_value:.4f}\")\n",
    "print(f\"RF MAE: {-study_rf.best_value:.4f}\")\n",
    "print(f\"LGBM MAE: {-study_lgbm.best_value:.4f}\")\n",
    "print(f\"XGB MAE: {-study_xgb.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b28657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE      RMSE        R2\n",
      "0  Linear Regression (Baseline)  0.061925  0.092850  0.992271\n",
      "4                       XGBoost  0.071231  0.111690  0.988816\n",
      "1                           SVR  0.072682  0.120805  0.986916\n",
      "2                 Random Forest  0.076262  0.127864  0.985342\n",
      "3                      LightGBM  0.098769  0.152281  0.979209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Inisialisasi Model Final dengan Best Parameters dari Optuna\n",
    "models_final = {\n",
    "    \"Linear Regression (Baseline)\": LinearRegression(),\n",
    "    \"SVR\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVR(**study_svr.best_params))\n",
    "    ]),\n",
    "    \"Random Forest\": RandomForestRegressor(**study_rf.best_params, random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(**study_lgbm.best_params, random_state=42, verbose=-1),\n",
    "    \"XGBoost\": XGBRegressor(**study_xgb.best_params, random_state=42)\n",
    "}\n",
    "\n",
    "# 2. Proses Training Final & Evaluasi di Data Test (20%)\n",
    "final_results = []\n",
    "\n",
    "for name, model in models_final.items():\n",
    "    # Training menggunakan 80% data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediksi menggunakan 20% data uji\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Perhitungan Metrik Evaluasi\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    final_results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "# 3. Menampilkan Tabel Perbandingan Akhir\n",
    "df_final = pd.DataFrame(final_results).sort_values(by=\"MAE\")\n",
    "print(df_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
